{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What I learned when trying to transcribe an audio file with Python\n",
    "\n",
    "\n",
    "## Overview\n",
    "Once a month I attend a meeting at my Department to discuss issues related to the Chemistry Undergraduate Course. An audio of the meeting is recorded with the help of a mobile phone, and later the secretary writes the respective minutes that are then filed after being approved by the participants.  In general, the recording time is about 2 hours long and there are eight participants who speak Brazilian Portuguese and have different accents.\n",
    "\n",
    "In an attempt to automate the transcription of this audio (named `meeting.wav`) and to make it one of my adventures with Python, I decided to use Python to get this job done.\n",
    "\n",
    "Since I have no previous knowledge about speech recognition, the process of converting audio into text, and because I don't want to recreate the wheel, I'll use already built programs and ideas (references include) and try to adapt them to solve the described problem. Moreover, I hope I'll learn a little bit about speech recognition, audio transcription and Python.\n",
    "\n",
    "## Tools\n",
    "* [Python 3](https://www.python.org/)\n",
    "* [pydub](http://pydub.com/) module\n",
    "* [SpeechRecognition](https://github.com/Uberi/speech_recognition#readme) module\n",
    "* [FFmpeg.exe](https://ffmpeg.org/) program (record, convert and stream audio and video)\n",
    "* [JupyterLab](https://jupyterlab.readthedocs.io/en/stable/)\n",
    "* An audio editor (optional), as [Audacity](https://www.audacityteam.org/), for example. \n",
    "\n",
    "Python modules can be installed using `pip` or `conda` and after installing the program `ffmpeg.exe` don't forget to add it to the system `path`. An audio editor also can help to visualize the audio data and get some useful parameters like *silence threshold* in dB and *silence lenght in miliseconds*. \n",
    "\n",
    "## Automatic speech recognition (ASR) system\n",
    "In general, an ASR system can be represented by the following simplified diagram:\n",
    "\n",
    "![Speech recognition diagram](img/speech.jpg)\n",
    "\n",
    "where a digital audio input, obtained from a previously recorded file/microphone, is processed by an automatic speech recognition system, responsible for the painful task of interpreting human speech by a computer, and provides as an output the desired transcribed text. On internet, you can find a lot of useful information about speech recognition with Python, but I started with:\n",
    "[The ultimate guide to speech recognition with Python](https://realpython.com/python-speech-recognition/) and [Speech recognition is hard](https://towardsdatascience.com/speech-recognition-is-hard-part-1-258e813b6eb7).\n",
    "\n",
    "The speech recognition process can be implemented by using an online API (Application Programming Interface). Some APIs' examples are:\n",
    "* [Assemblyai](https://pypi.org/project/assemblyai/)\n",
    "* [Google Cloud Speech](https://pypi.org/project/google-cloud-speech/)\n",
    "* [IBM Watson](https://pypi.org/project/watson-developer-cloud/) \n",
    "* [Pocketsphinx](https://pypi.org/project/pocketsphinx/)\n",
    "* [SpeechRecognition](https://pypi.org/project/SpeechRecognition/)\n",
    "\n",
    "The package used here is *SpeechRecognition* with the *Google Web Speech API* because it doesn't require an account and it is easy to use. It should be noted that this API comes with a default key and don't requires any authentication, however since Google may revoke it at any time it should be used only for testing purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. An idealized audio model\n",
    "This was the first [python tutorial](https://pythonbasics.org/transcribe-audio/#Installprequisites) I found useful to started with. I used it to transcribe the audio `harvard.wav` I found on [GitHub](https://github.com/realpython/python-speech-recognition) just to see how it would perform. Even though the input language of this audio is English, the speech recognition engine also supports other languages. And, since I used an audio file in .wav, I didn't need to convert it to .mp3.\n",
    " \n",
    "The program will perform the following actions to get the audio transcripted:\n",
    "* convert from a .mp3 to a .wav audio file\n",
    "* load the audio file\n",
    "* use a speech recognition engine\n",
    "\n",
    "The output will be the transcription of the original audio file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: the stale smell of old beer lingers it takes heat to bring out the odor a cold dip restores health and zest a salt pickle taste fine with ham tacos al Pastore are my favorite a zestful food is be hot cross bun\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# convert mp3 file to wav                                                       \n",
    "# sound = AudioSegment.from_mp3(\"harvard.mp3\")\n",
    "# sound.export(\"harvard.wav\", format=\"wav\")\n",
    "\n",
    "# transcribe audio file                                                         \n",
    "AUDIO_FILE = \"harvard.wav\"\n",
    "\n",
    "# use the audio file as the audio source                                        \n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)  # read the entire audio file                  \n",
    "\n",
    "        print(\"Transcription: \" + r.recognize_google(audio))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transcription of the audio file `harvard.wav`, presented above, was precise.\n",
    "\n",
    "Since I want to transcribe an audio from Brazilian Portuguese I asked four different people to read a short passage from \"The Art of War\" in Portuguese, and recorded with my mobile phone. The resulting audio files were then converted from .3gpp format to .wav using FFmpeg:\n",
    "\n",
    "`ffmpeg -i file.3gpp file.wav`\n",
    "\n",
    "I also set the language to Brazilian Portuguese in the speech recognition engine:\n",
    "`print(\"Transcription: \" + r.recognize_google(audio, language='pt-BR'))`\n",
    "\n",
    "The speakers in these audio files are from different gender, ages and accents, the reading was paused and the ambient noise was minimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Speaker 1:\n",
      "\n",
      " Transcription: comandar muitos é o mesmo que comandar poucos tudo é uma questão de organização controlar muitos ou poucos é uma mesma e única coisa é apenas uma questão de formação e sinalizações\n",
      "\n",
      "Speaker 2:\n",
      "\n",
      " Transcription: como andar muito é o mesmo que comandar pouco tudo é uma questão de organização controlar muito ou pouco é uma mesma e única coisa e apenas uma questão de formação e sinalizações\n",
      "\n",
      "Speaker 3:\n",
      "\n",
      " Transcription: comandar muitos é o mesmo que comandar poucos tudo uma questão de organização controlar muitos ou poucos é uma mesma e única coisa é apenas uma questão de formação e sinalizações\n",
      "\n",
      "Speaker 4:\n",
      "\n",
      " Transcription: comandar muitos é o mesmo que comandar poucos tudo é uma questão de organização controlar muitos ou poucos é uma mesma e única coisa é apenas uma questão de formação e sinalizações\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# convert mp3 file to wav                                                       \n",
    "# sound = AudioSegment.from_mp3(\"harvard.mp3\")\n",
    "# sound.export(\"harvard.wav\", format=\"wav\")\n",
    "\n",
    "# loop over four audio files \n",
    "for i in range(1,5):\n",
    "    AUDIO_FILE = \"speaker\"+str(i)+\".wav\"\n",
    "\n",
    "# use the audio file as the audio source                                        \n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)  # read the entire audio file                  \n",
    "\n",
    "        print(f'\\nSpeaker {i}:\\n')\n",
    "        print(\" Transcription: \" + r.recognize_google(audio, language='pt-Br'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transcriptions these audio files using `language='pt-Br'` are shown above, and were also precise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. A \"real world\" audio\n",
    "\n",
    "Now let's see how it will perform with a more \"real world\" messy audio file, that I previously mentioned . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# transcribe audio file                                                         \n",
    "AUDIO_FILE = \"meeting.wav\"\n",
    "\n",
    "# use the audio file as the audio source                                        \n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)  # read the entire audio file                  \n",
    "\n",
    "        print(\"Transcription: \" + r.recognize_google(audio, language='pt-BR'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the program returned several errors (not shown) when trying to transcribe my real, 2 hours long, audio file. I [found](https://www.geeksforgeeks.org/python-speech-recognition-on-large-audio-files/) that the speech recognition process accuracy decreases for long audio files and the Google Speech Recognition API can't recognize long audio files with reasonable accuracy. Moreover, the recording quality issue also must be considered, as well as the quality and speed of internet connection. The audio size problem can be addressed in two ways:\n",
    "* First, by dividing the original file into small chunks using as criterion of division, the silence threshold, i.e., the pauses we make between sentences. The problem here is the choice of the duration of this pause, different people pause for different times. In this case, I used a more elaborated [code](https://www.geeksforgeeks.org/python-speech-recognition-on-large-audio-files/).\n",
    "* Second, by splitting the original file into small chunks of a defined length, as 30 s for example, using FFmpeg: `ffmpeg -i meeting.wav -f segment -segment_time 30 -c copy chunk%d.wav`. In this case, I used a modified version of the first code presented here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Processing large audio files: silence threshold criterion\n",
    "I tried different combinations of the variables `min_silence_len` (e.g., 500 ms, 1000 ms and 2000 ms) and `silence_thresh` (e.g., -16, -22, -30, -42, -50). An audio editor can be very helpful here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries \n",
    "import speech_recognition as sr \n",
    "import os  \n",
    "from pydub import AudioSegment \n",
    "from pydub.silence import split_on_silence \n",
    "  \n",
    "# this function splits the audio file into chunks \n",
    "# and applies speech recognition \n",
    "def silence_based_conversion(path = \"my_audio.wav\"): \n",
    "    # open the audio file stored in \n",
    "    # the local system as a wav file. \n",
    "    song = AudioSegment.from_wav(path) \n",
    "  \n",
    "    # open two files: in the first one it will concatenate   \n",
    "    # and store the recognized text and in the second one\n",
    "    # it will write some error messages\n",
    "    fh = open(\"transcribed.txt\", \"w+\")\n",
    "    flog = open(\"transcribed.log\", \"w+\")\n",
    "          \n",
    "    # split track where silence is 0.5 seconds  \n",
    "    # or more and get chunks \n",
    "    chunks = split_on_silence(song, \n",
    "        # must be silent for at least 0.5 seconds \n",
    "        # or 500 ms. adjust this value based on user \n",
    "        # requirement. if the speaker stays silent for  \n",
    "        # longer, increase this value. else, decrease it. \n",
    "        min_silence_len = 2000, \n",
    "  \n",
    "        # consider it silent if quieter than -16 dBFS \n",
    "        # adjust this per requirement \n",
    "        silence_thresh = -50\n",
    "    ) \n",
    "  \n",
    "    # create a directory to store the audio chunks. \n",
    "    try: \n",
    "        os.mkdir('chunks') \n",
    "    except(FileExistsError): \n",
    "        pass\n",
    "  \n",
    "    # move into the directory to \n",
    "    # store the audio files. \n",
    "    os.chdir('chunks') \n",
    "  \n",
    "    i = 0\n",
    "    # process each chunk \n",
    "    for chunk in chunks:       \n",
    "        # Create 0.5 seconds silence chunk \n",
    "        chunk_silent = AudioSegment.silent(duration = 10) \n",
    "  \n",
    "        # add 0.5 sec silence to beginning and  \n",
    "        # end of audio chunk. This is done so that \n",
    "        # it doesn't seem abruptly sliced. \n",
    "        audio_chunk = chunk_silent + chunk + chunk_silent \n",
    "  \n",
    "        # export audio chunk and save it in  \n",
    "        # the current directory. \n",
    "        print(\"saving chunk{0}.wav\".format(i)) \n",
    "        # specify the bitrate to be 192 k \n",
    "        audio_chunk.export(\"./chunk{0}.wav\".format(i), bitrate ='192k', format =\"wav\") \n",
    "  \n",
    "        # the name of the newly created chunk \n",
    "        filename = 'chunk'+str(i)+'.wav'\n",
    "  \n",
    "        print(\"Processing chunk \"+str(i)) \n",
    "  \n",
    "        # get the name of the newly created chunk \n",
    "        # in the AUDIO_FILE variable for later use. \n",
    "        file = filename \n",
    "  \n",
    "        # create a speech recognition object \n",
    "        r = sr.Recognizer() \n",
    "  \n",
    "        # recognize the chunk \n",
    "        with sr.AudioFile(file) as source: \n",
    "            # remove this if it is not working \n",
    "            # correctly. \n",
    "            r.adjust_for_ambient_noise(source) \n",
    "            audio_listened = r.listen(source) \n",
    "  \n",
    "        # try converting it to text \n",
    "        try: \n",
    "            rec = r.recognize_google(audio_listened, language = 'pt-Br') \n",
    "            # write the output to the file. \n",
    "            fh.write(rec+\". \") \n",
    "  \n",
    "        # catch any errors. \n",
    "        except sr.UnknownValueError:\n",
    "            # write the output to the file. \n",
    "            flog.write(f\"file = {filename}: could not understand audio\")\n",
    "  \n",
    "        except sr.RequestError as e:\n",
    "            # write the output to the file. \n",
    "            flog.write(f\"file = {filename}: could not request results. check you internet connection\")\n",
    "  \n",
    "        i += 1\n",
    "  \n",
    "    os.chdir('..') \n",
    "  \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    silence_based_conversion(path = 'meeting.wav')   # set the name of the audio file that should be transcribed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Processing large audio files: file size criterion\n",
    "I split the original file in parts of 30 s and 60 s each part using FFmpeg as mentioned before. Since the audio files were already created I just looped through the chunk files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import speech_recognition as sr\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# open two files, to store the recognized text and\n",
    "# to store error messages\n",
    "fh = open(\"transcription.txt\", \"w+\")\n",
    "flog = open(\"transcription.log\", \"w+\")\n",
    "  \n",
    "# loop through audio chunks\n",
    "for i in range(0, 116):      # set the range of the chunks\n",
    "    filename = 'chunks/chunk'+str(i)+'.wav'\n",
    "    print(f'i = {i} | filename = {filename}\\n')\n",
    "    file = filename\n",
    "\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(file) as source:\n",
    "#        r.adjust_for_ambient_noise(source, duration=4000)\n",
    "        audio = r.listen(source)\n",
    "    \n",
    "    # try converting it to text \n",
    "    try:\n",
    "        rec = r.recognize_google(audio, language = 'pt-BR')\n",
    "        fh.write(rec+\". \") \n",
    "    \n",
    "    # catch any errors    \n",
    "    except sr.UnknownValueError:\n",
    "        flog.write(f\"file = {filename}: could not understand audio\")\n",
    "        \n",
    "    except sr.RequestError as e:\n",
    "        flog.write(f\"file = {filename}: could not request results. check you internet connection\")\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Concluding remarks\n",
    "\n",
    "From the two methods used here, I was able to extract more text using the second one, but in both cases, the quality of the transcribed text is far from reality. The audio used was registered using a mobile phone, so it doesn't have a high quality. However, I believe that the greatest difficulty in transcription was caused by the way of speaking of the participants who speak with different accents and dialects or speak very fast and don't separate words and sentences what makes their speech unclear to the engine, without using a more sophisticated and trained algorithm. Many other factors like age, gender, context, intent, etc, also can affect the recognition process.\n",
    "\n",
    "[Human speech is not a simple phenomenon](https://www.youtube.com/watch?v=FZ0PDJbRU5I) and it is influenced by many complex factors that are constantly changing as we change who speak. Machines recognition systems work much better in ideal conditions where we can reduce noise level and the speak is paced. Fortunately, there are algorithms and techniques more sophisticated to tackle this problem but this is not the subject here.\n",
    "\n",
    "The main goal was to use Python to try to solve a particular problem while learning Python itself and Jupyter Lab. This was my first personal project in Python so there is much to improve."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
